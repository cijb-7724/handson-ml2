9.1.5 半教師あり学習の一部としてのクラスタリング
・ラベル伝播
ラベルなしのインスタンスについてクラスタリングをして，代表インスタンスに対して手作業で
ラベリングを行う．同じクラスタに含まれるインスタンスのラベルを代表インスタンスのラベルとする．
これだけではだめ，
クラスタ境界に近いインスタンスには，間違ったラベルがつけられる可能性があるから．
重心に近い20%のインスタンスだけにラベルイングをする．→さらに性能が上がる．

・能動学習
すべてのラベル付きインスタンスでモデルを学習し，ラベルなしインスタンスを予測したとき，
予測確率が最も低いインスタンスのラベルを専門家に尋ねるなど．

9.1.6 DBSCAN
ε近傍内にmin-sanple個のインスタンスがあったらそのインスタンスは「コアインスタンス」
コアインスタンスでなく，近くにコアインスタンスのないインスタンスは異常値のみなされる．
クラスタによって密度が大きく異なる場合は，適切に機能するとは限らない．

9.1.7 その他のクラスタリングアルゴリズム
・凝縮クラスタリング クラスタの二分木
・BIRCH 大規模なデータセットを使う目的で設計．高速でK平均法と同様の結果．
・平均値シフト法 DBSCANに似てる
・アフィニティ伝播法 投票システムを使う．個々のインスタンスは自分の代表として類似インスタンスを投票し，収束する．
・スペクトラルクラスタリング インスタンス間の類似度行列を入力として，次元削減をする．

9.2 混合ガウスモデル
混合ガウスモデルGMM(gaussian mixture model)
EM法：ｋ平均法の一般形
混合ガウスモデルは生成的なモデル：モデルから新しいインスタンスをサンプリングすることができる．
データが楕円体に分布しているとうまくいくっぽい．yes
クラスタ数が多く，インスタンスが少ないとEMは最適解に収束するのが困難．パラーメータを制限する．

9.2.1 混合ガウスモデルを使った異常検知
異常検知（外れ値検知）→詐欺検知，製造ラインの不良品検知，前処理としての外れ値除去などの応用分野がある．
新規検知：アルゴリズムがクリーンなデータセットで訓練されることが前提となっている点で上と異なる．

9.2.2 クラスタ数の選択
ベイズ情報量基準(BIC)，赤池情報量基準(AIC)
ともに，学習するパラメータが多いモデルにペナルティを与え，データによく適合するモデルに報酬を与える．

9.2.3 混合ベイズガウスモデル
最適なクラスタ数を機械的に探す方法．ある程度タスクに知識があることが前提で，クラスタ数を決めると，
不要なクラスタを削除してくれる．

9.2.4 以上/新規検知のためのその他のアルゴリズム
任意の形のクラスタを扱える，クラスタリングアルゴリズムたち．
・PCA
・Fast-MCD
・アイソレーション
・LOF
・1クラスSVM

9.3 演習問題
1. あなたならクラスタリングをどのように定義するか．また，クラスタリングアルゴリズムをいくつか挙げなさい．
ラベルのないデータ群を適切にグループ分けすること．
k平均法・混合ガウスモデル，
A>>DBSCAN, 平均値シフト法，アフィニティ伝播法，

2. クラスタリングアルゴリズムの主要な応用分野をいくつか挙げなさい．
（画像）セグメンテーション，詐欺検知，新規検知，特徴量削減，半教師あり学習のラベル付け

3. k平均法を使うときに適切なクラスタ数を選択するための方法を2つ説明しなさい．
混合ベイズガウスモデルを使う．
A>>
・クラスタ数の関数としての慣性（各インスタンスから最近傍重心までの距離の平均二乗距離）のグラフを書き，
慣性の低下が止まる肘を探す．
・クラスタ数の関数としてのシルエットスコアのグラフを描く．
ピークになる点が現れることが多く，最適なクラスタ数はその近くにある．

4. ラベル伝播とは何か．なぜそのようなものを実装するのか．またどうすれば実装できるか，説明しなさい．
半教師あり学習において，ラベルを付ける際クラスタリングを行い，そのクラスタ重心のラベルを疎のクラスタに属する
インスタンスのラベルとする．

5. 大規模なデータセットに対するスケーラビリティが高いクラスタリングアルゴリズムを2つ挙げなさい．
A>>ｋ平均法とBIRCH
また，高密度の領域を探すクラスタリングアルゴリズムを2つ挙げなさい．
>>DBSCANと平均シフト法

6. 能動学習が役立つユースケースを挙げなさい．
A>>ラベルなしインスタンスが多数あるが，ラベル付けにはコストがかかるとき
また，どのように実装するか答えなさい．
>>インスタンスを無作為に選ぶのではなく，アルゴリズムが最も自信のない解答をしたインスタンスから専門家に尋ねる

7. 異常検知と新規検知の違いは何か．
モデルの学習時にクリーンのデータのみを使用しているのが新規検知．
A
異常検知は外れ値が含まれるかもしれないデータセットで訓練をする．

8. 混合ガウスモデルとは何か，どのようなタスクで使えるか．
クラスタが楕円体の形状で分布しているとき．
A
複数のパラメータがわからないガウス分布を混ぜ合わせたものからインスタンスが生成されていると仮定する確率的なモデル．
データが有限個の楕円形のクラスタにまとまっていることを前提としている．
ただし，それらの楕円形の形状，サイズ，向き，密度などはまちまちでよい．
そして，個々のインスタンスがどのクラスタに含まれるかはわかっていない．
>>密度推定，クラスタリング，異常検知

9. 混合ガウスモデルを使っているときに，適切なクラスタ数を見つけるための2つのテクニックとは何か．
混合ベイズガウスモデル，
A>>クラスタ数の関数として，ベイズ情報基準や赤池情報基準をプロットし，BICやAICを最小化するクラスタ数を選ぶ．
