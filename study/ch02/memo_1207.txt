2.5.2 テキスト/カテゴリ属性の処理
ocean_proximityはテキストだた，カテゴリ属性である．
テキストラベルを数値に変換する．
特徴量としてのテキストカテゴリ属性を数値のカテゴリ属性に変換する際，
カテゴリ0, 1, 2, 3としたときに，0と3よりも0と1の方が近いと勘違いされていしまう．
そこでワンホット表現を用いる．ワンホットエンコーディング．これもscikit-learnにある．

SciPyの疎行列を用いることで，膨大なメモリの節約になる．なぜなら，0以外の場所を記録してくれるから．

カテゴリ属性に含まれるカテゴリが多数になる場合，ワンホットエンコーディングを使うと入力特徴量が大量になり，
訓練に時間がかかるようになり，性能が下がる場合がある．
そんな時は，数値特徴量への変換ができるとよい．
ocean_proximityは太平洋からの距離，
国コードは人口1人当たりのGDPなど
表現学習とよばれ，13, 17章で詳しくやる

2.5.3 カスタム変換器
ハイパーパラメータを追加すれば，自分では確信をもてないデータ準備のステップをオン／オフできて，良い組み合わせを見つけられやすくなる．

2.5.4 特徴量スケーリング
重要な変換の1つ，特徴量のスケーリング(feature scaling)．
機械学習のアルゴリズムはほぼ例外ないく，入力の数値属性のスケールが大きく異なると性能を発揮できない．
ターゲットのスケーリングは一般には不要．

・最小最大スケーリング(min-max scaling)=正規化(normalization)
0~1の範囲に収まるようにスケーリングしなおす．
x <- (x - min) / (max - min)
scikit-learnではMinMaxScalerでできる．feature_rangeハイパーパラメータで任意の範囲に変えることもできる

・標準化(standarization)
x <- (x - avg) / sig^2
変換後の平均値は0，正規化と違って上限下限がないので一部のアルゴリズムには不向き
例えばニューラルネットワークでは入力値が0から1に収まっていることを前提とすることが多い，
利点は外れ値の影響が小さくなること（確かに！！正規化だと校長がいるとよくなさそう）
scikit-learnではStandardScalerという変換器がある

ほかの変換と同様に，訓練データだけにスケーラを適合させることが大切．
テストセット，訓練セットの両方で変換を付けるのは，そのように適合させたときだけ．

2.5.5 変換パイプライン
データ変換のステップはいくつもあり，正しい順序で実行しなければならない．
scikit-learnには，変換シーケンスを実行しやすくするPipelineクラスがある．





