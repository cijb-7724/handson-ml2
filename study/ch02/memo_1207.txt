2.5.2 テキスト/カテゴリ属性の処理
ocean_proximityはテキストだた，カテゴリ属性である．
テキストラベルを数値に変換する．
特徴量としてのテキストカテゴリ属性を数値のカテゴリ属性に変換する際，
カテゴリ0, 1, 2, 3としたときに，0と3よりも0と1の方が近いと勘違いされていしまう．
そこでワンホット表現を用いる．ワンホットエンコーディング．これもscikit-learnにある．

SciPyの疎行列を用いることで，膨大なメモリの節約になる．なぜなら，0以外の場所を記録してくれるから．

カテゴリ属性に含まれるカテゴリが多数になる場合，ワンホットエンコーディングを使うと入力特徴量が大量になり，
訓練に時間がかかるようになり，性能が下がる場合がある．
そんな時は，数値特徴量への変換ができるとよい．
ocean_proximityは太平洋からの距離，
国コードは人口1人当たりのGDPなど
表現学習とよばれ，13, 17章で詳しくやる

2.5.3 カスタム変換器
ハイパーパラメータを追加すれば，自分では確信をもてないデータ準備のステップをオン／オフできて，良い組み合わせを見つけられやすくなる．

2.5.4 特徴量スケーリング
重要な変換の1つ，特徴量のスケーリング(feature scaling)．
機械学習のアルゴリズムはほぼ例外ないく，入力の数値属性のスケールが大きく異なると性能を発揮できない．
ターゲットのスケーリングは一般には不要．

・最小最大スケーリング(min-max scaling)=正規化(normalization)
0~1の範囲に収まるようにスケーリングしなおす．
x <- (x - min) / (max - min)
scikit-learnではMinMaxScalerでできる．feature_rangeハイパーパラメータで任意の範囲に変えることもできる

・標準化(standarization)
x <- (x - avg) / sig^2
変換後の平均値は0，正規化と違って上限下限がないので一部のアルゴリズムには不向き
例えばニューラルネットワークでは入力値が0から1に収まっていることを前提とすることが多い，
利点は外れ値の影響が小さくなること（確かに！！正規化だと校長がいるとよくなさそう）
scikit-learnではStandardScalerという変換器がある

ほかの変換と同様に，訓練データだけにスケーラを適合させることが大切．
テストセット，訓練セットの両方で変換を付けるのは，そのように適合させたときだけ．

2.5.5 変換パイプライン
データ変換のステップはいくつもあり，正しい順序で実行しなければならない．
scikit-learnには，変換シーケンスを実行しやすくするPipelineクラスがある．

ColumnTransformerはpandasのDataFrameとの相性が抜群．
これを使って住宅価格データのすべてを変換する．

2.6 モデルを選択して訓練する
ついにここまで来た！
・問題の枠組みを明らかにする
・データを入手，研究
・データセットを訓練セットとテストセットに分ける
・機械学習アルゴリズムのためにデータを自動的にクリーンアップする
・機械学習のモデルを選択する（いまここ

2.6.1 訓練セットを訓練，評価する
回帰分析では誤差が大きい
決定木を使った複雑なモデルでやってみると誤差が0となった．
過学習している可能性が高いため，次で交差検証を行う．

2.6.2 交差検証を使ったより良い評価
train_test_split()関数を使って，訓練セットを元のものよりも小さい訓練セットと検証セットに分割し，
新しい訓練セットでモデルを訓練して，検証セットで評価する．
scikit-learnのk分割交差検証
フォールド(fold)と呼ばれる10個の別々のサブセットに無作為に分割し，
1個のフォールドを評価用に残し，その他9個のフォールで訓練して，決定木モデルを10回訓練・評価する．
すると10個のスコアを並べたベクトルが得られる．

交差検証の結果，決定木はあまり優れていないようだ．
交差検証はモデルの性能を推定するだけでなく，推計がどれほど正確か（標準偏差）も測定できる．

決定木は線形回帰モデルよりも性能が悪いとわかった．
次にランダムフォレストを試す．詳しくは7章．
これもよさそうだけど，過学習が起きている．
目標は小数の期待できるモデルのリストを作ることなので深入りせずほかのアルゴリズムを試すべき（SVMやNNなど）．

2.7 モデルを微調整する
期待できそうなモデルのリストができたらモデルを微調整する．
そのいくつかの方法を見る．

2.7.1 グリッドサーチ
ハイパーパラメータをマニュアルで試すのは大変
scikit-learnのGridSearchCVに探させる．
ハイパーパラメータの取るべき値は連続したa(=10)のべき乗を試すとよい．

2.7.2 ランダムサーチ
ハイパーパラメータの探索空間が大きいときには，RandomizedSearchCVを使った方が良い場合が多い．
指定された回数，無作為に値を選ぶ．

2.7.3 アンサンブルメソッド
性能の良いモデルを組み合わせること

2.7.4 最良のモデルと誤差の分析
最良のモデルを調べると，問題について優れた知見が得らえるかも．
RandomForestRegressorは正確な予測のために個々の属性の相対的な重要度の大小を示すことができる．
そこから役に立たない特徴量が見つかるかも
ocean_proximityカテゴリが役に立ってなさそう．

