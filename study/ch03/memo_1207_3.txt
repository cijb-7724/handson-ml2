3章 分類
1章で教師あり学習のタスクで最も一般的なものは回帰と分類だと説明した．
2章では回帰をやったのでここでは分類をやる．

3.1 MNIST
機械学習のHello World
新しい分類アルゴリズムが出るたびに，MNISTの性能に関心が集まる

一部の学習アルゴリズムでは訓練インスタンスの順序に影響を受け，同じようなインスタンスが立て続けに登場すると
性能が劣化する（ゼロ作１でやらかしたかも）

3.2 二項分類器の訓練
問題を単純化して1個の数字だけを識別できるようにする（5かそうでないか（ローランド））．
確率的勾配降下法の分類気から試してみる
オンライン学習にも向いている

3.3 性能指標
分類気の評価は回帰の評価よりもはるかに難しい．

3.3.1 交差検証を使った正解率の測定
自分でこれを実装するとき，フォールドを作る際も層化抽出を行う
SGDを交差検証で正解率を計算すると約95%正解．
すべてを5でないと判定するモデルの正解率は約90％正解．
分類器の性能指標として正解率が一般に好まれない理由がこれ．

3.3.2 混同行列
学校の統計の授業などで既出だったのですんなり入ってきた．
分類器が５の画像を３と混同した回数は５行３列を見ればいい
混同行列の行：実際のクラス
混同行列の列：予測したクラス
陰性のものを正しく陰性と判断した：真陰性(true negative)
陰性のものを誤って陽性と判断した：偽陽性(false positive)
陽性のものを誤って陰性と判断した：偽陰性(false negative)
陽性のものを正しく陽性と判断した：真陽性(true positive)
適合率precision = TP / (TP + FP)
再現率recall = TP / (TP + FN)

3.3.3 適合率と再現率
2つの分類器を比較する方法として適合率と再現率の調和平均(harmonic mean)を取る方法がある=F値
f1_score()
F値は適合率と再現率が両方高いときに高くなる．
しかし，片方だけが重視される場合はF値は望ましくない指標である．

3.3.4 適合率と再現率のトレードオフ
なぜトレードオフなのか
決定関数の閾値があるから

閾値を変化させたときの適合率と再現率をプロットすると，曲線が交差する．
その交点の閾値をThresholdという．
適合率だけを気にして分類器を設計すると再現率が低すぎたりして，実用レベルにならない可能性がある．

3.3.5 ROC曲線
二幸分類ではROC曲線(receiver operating characteristic:受信者動作特性曲線)
偽陽性率(FPR:false positive ratio)に対する真陽性率(TPR:true positive rate，再現率のもう一つの名前)をプロットしたもの．
=1-真陰性率(TNR:true negative ratio)
TNR特異度ともよばれる
1-特異度　に対する　感度(sensitivety:再現率)をプロットした曲線ともいえる

ROC曲線を描くためには，roc_curve()関数を使って様々な閾値でTPRとFPRを計算する．
これもトレードオフになる．TPRが上がるとFPRも上がる．
優れた分類器はROC曲線が線形グラフから左上の方に離れた位置を通る．

分類器の比較にはAUC(area under the curve)が使える．
完璧な分類器はAUC=1である．無作為の分類器の場合はROC AUC = 0.5になる．
ROC AUCを計算するのもsklearn.metrics.roc_auc_scoreでできる．

PR曲線とROC曲線の使い分け
陽性クラスが珍しいとか，偽陰性よりも偽陽性の方が気なる時にPR
それ以外はROC

二幸分類の訓練，タスクの適切な指標の選択，交差検証を使った分類の評価，
ニーズに合った適合率／再現率のバランスの取り方，AUCスコアを学んだ．

 3.4 多クラス分類
 multinomial classifier
 
