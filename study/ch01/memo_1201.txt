1.4.1.4 強化学習
reinforcement learning
大学のゼミで，ゼロから作るdeep learning 4 強化学習編を勉強していたので大体知っていた．
エージェントagentが環境内で行動を選択し，報酬rewardを得る．エージェントは方策policyと呼ばれる戦略を自分で学習していき，その総和が最大となること目指す．

1.4.2 バッチ学習とオンライン学習
1.4.2.1 バッチ学習
batch learningでは，システムは少しずつ学習することはできない．
すべての訓練データを一気に学習するため，大量の時間と計算資源が必要になるので，オフラインで行われることが多い．
完全なデータセットを使って0から新バージョンのシステムを訓練しなければいけない．
株価予測など変化の激しいデータには対応できない．

1.4.2.2 オンライン学習
online learningでは，1つずつ，あるいはミニバッチ(mini-batch)と呼ばれる小さなグループで少しずつインスタンスデータを与え，訓練をする．ストレージスペースを大幅に削減できる．
オンライン学習は，1台のマシンのメインメモリに入りきらないほど大きな訓練データを一部ロードして学習するという使い方もできる（アウトオブコアout-of-core）
オンライン学習の大きな問題は，システムに不良なデータが与えられると，システムの性能が次第に下がっていくこと．

1.4.3 インスタンスベース学習とモデルベース学習
汎化(generalize)の方法によっても分類できる．
機械学習のタスクの大半は予測＝汎化．汎化は2つの主要なアプローチがある．

1.4.3.1 インスタンスベース学習
instance-based learning
既知のスパムメールによく似ているメールもそう分類したい．
そのとき2つのメールの類似度の尺度(measure of similarity)が必要．
システムはデータ例を丸暗記し，新しいケースに対しては，類似度の尺度を使って学習したデータ例と比較，汎化するもの．

1.4.3.2 モデルベース学習
model-based learning
データ例全体からモデルを構築し，そのモデルを使って予測をする手法．
・データを検討
・モデルを選択（線形回帰）
・訓練データに基づいてモデルを訓練
・新しいケースに対してモデルを適用し，予測（推論）を行う
という流れ．

キプロスの暮らしの満足度を計算するコードを写経して実際に動かしてみた．

1.5 機械学習が抱える難問
1.5.1 訓練データ例の品質の低さ
理屈を超えたデータの有効性
・十分なデータを与えれば，非常に異なる機械学習アルゴリズムが複雑な自然言語の曖昧性解消もんだに対して同程度の性能を出すことが明らかになった．
・複雑な問題では，アルゴリズムよりもデータの方が大切 -2009

1.5.2 現実を代表しているとは言えない訓練データ
現実を代表できていない訓練データを使うと，正しい予測ができない．
サンプリングが小さいと，サンプリングノイズが大きくなる．
サンプリングが大きくても，サンプリングの方法に欠陥があれば，代表的なデータを集められない．これをサンプリングバイアスと呼ぶ．
生存者バイアス的な感じだ．

1.5.3 品質の低いデータ
訓練データの誤り，外れ値，ノイズをクリーンアップするために多くの時間を割く．
具体的には．．．
・一部のインスタンスが明らかに外れ値なら，単純に取り除くか，手作業で誤りを修正した方が良い．
・一部のインスタンスがいくつかの特徴量を持たない場合，属性を完全に無視してしまうか，それらのインスタンスを無視するか，欠損値を補うか，特徴量を持つモデルと持たないモデルを訓練するかといった対策の中から適切なものを選ぶ．

1.5.4 無関係な特徴量
適切な特徴量をそろえることが大切．
特徴量エンジニアリング(feature engineering)
・特徴量選択(feature selection) 既存の特徴量から訓練に最も役立つ特徴量を選択
・特徴量抽出(feature extraction) 既存の特徴量を組み合わせて，より役立つ1つの特徴量を作る＝次元削減アルゴリズムに役立つ
・新データの収集による新しい特徴量の作成