7章 アンサンブル学習とランダムフォレスト
アンサンブル：予測器のグループ
アンサンブル学習：アンサンブルの中で最も優れている1つの結果を使う
ランダムフォレスト：決定木のアンサンブル
バギング・ブースティング・スタッキング

7.1 投票分類器
ロジスティック回帰分類器，SVM分類器，ランダムフォレスト分類器，K近傍分類器，
それぞれ80%の性能だとする．
これらの多数決の分類器をハード投票分類器と呼ぶ．
アンサンブルは強学習器になる
アンサンブルで性能を上げるためには，独立でないといけない．つまり同じ訓練データを用いてはいけない．
大きく異なるアルゴリズムでやるのもよい
ソフト投票：最も確率の高い分類器の結果を用いる．
ソフト＞ハードの性能

7.2 バギングとペースティング
多様性の高い分類器のアンサンブルと，無作為に別々のサブセットをサンプリングして訓練する．
訓練セットのサンプリング
重複あり：バギング
重複なし：ペースティング
同じ予測器が同じ訓練インスタンスを呼び出せるの：バギング
集計関数
分類：統計モード（最頻値）
回帰：平均値
並列にそれぞれのモデルを訓練できる点もよい．

7.2.1 scikit-learnにおけるバギングとペースティング
そういうクラスがある
CPUコア数を指定して並列化もできる
個々の予測器が訓練に使うサブセットの多様性が上がる
バギングの方が良い
余力があれば，バギングとペースティングで交差検証をしてよいほうを選ぶ

7.2.2 OOB検証
バギングである分類器では全く選ばれないインスタンスが37%ある( (1-1/m)^m m->inf　)
それらをOOBインスタンスという
個々の予測器のOOB検証を平均するとアンサンブル自体の検証結果になる

7.3 ランダムパッチとランダムサブスペース
特徴量のランダムなサンプリングもできる
高次元の入力に対して役立つ
訓練インスタンスと特徴量の両方をサンプリングすることをランダムパッチという
特徴量のみをサンプリングすることをランダムサブスペースという

7.4 ランダムフォレスト
特徴量の無作為なサブセットから最良の特徴量を探す．
木の多様性が増す．バイアスが上がる．分散が下がる．全体としてモデルの性能が上がる．

7.4.1 Extra-Tree
個々の木を育てる過程で，個々の閾値も無作為なものにする．さらに無作為性が上がってよい．
↑単純な無作為な木をExtremely Randomized Treesのアンサンブルと呼ぶ．

7.4.2 特徴量の重要度
ランダムフォレストは，各特徴量の相対的な重要度が簡単に測定できるようになる点でも優れている．
scikit-learnは訓練後に各特徴量に対してスコアを自動で計算し，確率表現で答える．
irisではがく片の長さ，幅は重要ではないらしい

7.5 ブースティング
複数の弱予測器を結合して強学習機を作るあらゆるアンサンブルメソッドを目指す．
よく使われるやつ
アダブースト（エイダブースト）適応的ブースティング
勾配ブースティング

7.5.1 アダブースト(AdaBoost)
前の予測器が過小適合した訓練インスタンスに少しだけ余分に注意を払い，新しい予測器は前の予測器を修正する．
難しい条件をどんどん深く学習していった新しい予測器が生まれる．これがアダブースト．
ベースとなる分類器（決定木）を訓練し，訓練セットを対象として予測する．
分類に失敗した訓練インスタンスの相対的な重みを上げる．
更新された重みを使って第2の分類器を訓練し，訓練セットの予測をして，重みを更新する．これを繰り返す．
アダブーストが過学習した　→　推定器の数を減らすorベース推定器を強く正規化する

7.5.2 勾配ブースティング
新予測器を前の予測器の残渣に適合させようとする．
勾配ブースティング回帰木
決定木が多すぎると過学習してしまう．
最適な決定木の数を決めるには，早期打ち切りを使う．staged_predict()
確率的勾配ブースティング

7.6 スタッキング
スタッキング（スタック汎化）
アンサンブルに含まれるすべての予測器の予測を集計するときに，
ハード投票のようなつまらない関数を使ったりせずに，集計まで行うようにモデルを訓練すればよいのでは？
予測値という新しいインスタンスに対して，回帰のタスクを行うそのようなアンサンブル
最後の予測器をブレンダ，メタ学習器という．
scikit-learnにスタッキングはない

7.7 演習問題
1. まったく同じ訓練データを使って5個の異なるモデルを訓練し，それらがすべての95%の適合率を達成したとき，
それらのモデルを組み合わせたらもっと良い結果が得られる可能性はあるか？
>>ある
もしそうだとすると，どうすればそのような結果が得られるか？
アンサンブル学習をする．5つのモデルでそれぞれ予測し，その最頻値を採用する．

2. ハード投票分類器とソフト投票分類器の違いは何か？
ハードは最頻値，ソフトは最も確率の高いモデルの結果を答えとする．
A ソフトは各クラスが最も高い確率を出力した確率の平均値のクラス

3. 複数のサーバーで分散処理することによってバギングアンサンブルのスピードを上げることはできるか，
>>できる
ペースティングアンサンブル>>できる
ランダムフォレスト>>逐次的だからできない
スタッキングアンサンブル>>逐次的だからできない
A
予測器が互いに独立しているのでバギング，ペースティング，ランダムフォレストはスピードが向上する可能性がある．
ブースティングは逐次的だからできない

4. OOB検証の長所は何か？
A OOBでは，バギングアンサンブルに含まれる個々の予測器は，訓練で使われていないインスタンスを使って検証される
そのため，別に検証セットを用意しなくても，かなりバイアスの低い形でアンサンブルを検証できる．
そのため，訓練のために使えるインスタンスが多くなり，アンサンブルの性能が少し上がる．

5. Extra-Trees分類器が通常のランダムフォレストよりも無作為的なのは何によるものか．
>>閾値すら
この余分に無作為的なことにはどのような意味があるか．
>>木に多様性が生まれる
Extra-Treesは通常のランダムフォレストと比べて遅いか，それとも速いか？
>>閾値の最適化をしないので速い．
A 訓練は早いけど予測の時は変わらない

6. 手元のアダブーストアンサンブルが過小適合している場合，どのハイパーパラメータをどのように調整すべきか．
A 推定器を増やすか，ベース推定器の正則化ハイパーパラメータを下げる（過学習を少し上げる）

7. 勾配ブースティングアンサンブルが訓練セットを過学習している場合，学習率を上げるべきか下げるべきか．
A 学習率は下げる．
また，予測器の台数として適切な値を探るために，早期打ち切り









